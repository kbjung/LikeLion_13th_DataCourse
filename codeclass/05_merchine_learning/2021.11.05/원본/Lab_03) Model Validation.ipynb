{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fHL3ONZ55I-"
   },
   "source": [
    "# Lab 3\n",
    "\n",
    "### Context\n",
    "#### Cross Validation\n",
    "+ The Set of Train, Valid, Test \n",
    "+ k-Fold Cross Validation with Stratify\n",
    "\n",
    "#### Ensemble\n",
    "+ Voting Ensemble\n",
    "+ Out-of-fold(OOF) Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aAfXTYpj5ysB"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dRCIwM8bDIma"
   },
   "outputs": [],
   "source": [
    "BASE_DIR = ''\n",
    "\n",
    "train_path = join(BASE_DIR, 'data', 'MDC14', 'train.csv')\n",
    "test_path  = join(BASE_DIR, 'data', 'MDC14', 'test.csv')\n",
    "\n",
    "data = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)\n",
    "\n",
    "label = data['credit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZJz8FKzeDImb"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BjzSSJrdDImc"
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KyMlpcWlDImc"
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BJ2WoVBnDImd"
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cpbzIK_VDIme"
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4LlL1pmxDImf"
   },
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VMTtBGedDImg"
   },
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UCQeb4zvDImg"
   },
   "outputs": [],
   "source": [
    "# 불필요한 컬럼 제거\n",
    "data.drop(columns=['index', 'credit'], inplace=True)\n",
    "test.drop(columns=['index'],           inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yinAftwCDImh"
   },
   "outputs": [],
   "source": [
    "cat_columns = [c for c, t in zip(data.dtypes.index, data.dtypes) if t == 'O'] \n",
    "num_columns = [c for c    in data.columns if c not in cat_columns]\n",
    "\n",
    "print('Categorical Columns: \\n{}\\n'.format(cat_columns))\n",
    "print('Numeric Columns: \\n{}'.format(num_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6FIGMULDImh"
   },
   "source": [
    "#### 라벨 데이터 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tA2nuXqvDImi"
   },
   "outputs": [],
   "source": [
    "label = label.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gL6vXphADImi"
   },
   "source": [
    "## Cross Validation\n",
    "### 1. Train, Valid, Test Set\n",
    "훈련, 검증, 테스트 데이터라고 부르는 3가지를 한번 이야기 해보겠습니다.<br>\n",
    "* Train Data : 모델을 학습하는데 사용하는 데이터 (모델이 알고 있는 학습할 데이터, 과거 데이터)\n",
    "* Valid Data : 학습한 모델의 성능을 검증하는 데이터 (모델이 모르는 학습하지 않을 데이터, 모델 검증에 사용하는 데이터, 과거 데이터)\n",
    "* Test Data : 학습한 모델로 예측할 데이터 (모델이 모르는 예측할 데이터, 미래 데이터)\n",
    "\n",
    "<img src='./img/train_val_test.png' style='height : 500px' >\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTzScJYlDImi"
   },
   "source": [
    "##### 데이터 쪼개기, Train -> (Train, Valid)\n",
    "- train_test_split 파라미터 \n",
    "    - test_size  (float): Valid(test)의 크기의 비율을 지정\n",
    "    - random_state (int): 데이터를 쪼갤 때 내부적으로 사용되는 난수 값 (해당 값을 지정하지 않으면 매번 달라집니다.)\n",
    "    - shuffle     (bool): 데이터를 쪼갤 때 섞을지 유무\n",
    "    - stratify   (array): Stratify란, 쪼개기 이전의 클래스 비율을 쪼개고 나서도 유지하기 위해 설정해야하는 값입니다. 클래스 라벨을 넣어주면 됩니다.\n",
    "        - ex) 원본 Train 데이터의 클래스 비율이 (7:3) 이었다면, 쪼개어진 Train, Valid(test) 데이터의 클래스 비율도 (7:3)이 됩니다. 당연히 분류 데이터에서만 사용할 수 있습니다.\n",
    "        \n",
    "#### ref\n",
    "- [검증 데이터가 필요한 이유 3months님 블로그](https://3months.tistory.com/118)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IH4J9wwcDImj"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 쪼개어진 Train, Valid 데이터의 비율은 (7:3), 내부 난수 값 42, 데이터를 쪼갤 때 섞으며 label 값으로 Stratify 하는 코드 입니다. random_state를 주석 처리하고 데이터를 확인해보시면 계속 바뀝니다.\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(data, label, \n",
    "                                                      test_size=0.3,\n",
    "                                                      random_state=42,\n",
    "                                                      shuffle=True,\n",
    "                                                      stratify=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6KQykVcyDImj"
   },
   "outputs": [],
   "source": [
    "data.shape, x_train.shape, x_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C7txcCWuDImk"
   },
   "source": [
    "### 2. k-fold with stratify\n",
    "k-fold는 데이터를 k개로 쪼개는 것을 말합니다. <br>\n",
    "일반적으로 Cross Validation에서 사용되며, 데이터셋을 k개로 쪼개어 k-1개로 모델을 학습하고, 1개로 모델을 검증합니다. <br>\n",
    "k개로 데이터를 쪼개면, 모든 fold에 대해(하나의 fold를 선택하여) 검증하는 방식으로 k번 다른 데이터셋으로 학습한 모델을 검증할 수 있습니다.\n",
    "\n",
    "![kfold](./img/kfold.png)\n",
    "\n",
    "#### Stratify, 계층적 k-fold는 뭔가요?\n",
    "k-fold는 데이터의 정렬 유무와 분류할 클래스의 비율에 상관없이 순서대로 데이터를 분할하는 특징이 있습니다.<br>\n",
    "하지만, 분류할 클래스의 비율이 다르다면 어떻게 될까요? 그런 경우에는, 각 fold가 학습 데이터셋을 대표한다고 말하기 어려워집니다.<br>\n",
    "한 fold에 특정 클래스가 많이 나올수도, 적게 나올수도 있기 때문입니다. Stratified k-fold는 그러한 문제점을 해결하기 위해 제안되었습니다.<br>\n",
    "k개의 fold도 분할한 이후에도, 전체 훈련 데이터의 클래스 비율과 각 fold가 가지고 있는 클래스의 비율을 맞추어 준다는 점이 기존의 k-fold와의 다른 특징 입니다. \n",
    "\n",
    "##### k-fold\n",
    "![kfold_example](./img/kfold_example.png)\n",
    "\n",
    "##### Stratified k-fold\n",
    "![stratified_kfold_example](./img/stratified_kfold_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gu2Vhu_SDImk"
   },
   "source": [
    "#### k-Fold\n",
    "k-fold는 말 그대로 데이터를 k개로 쪼갭니다. <br>\n",
    "k의 개수를 조절하여 몇개의 fold를 만들지 결정할 수 있습니다.\n",
    "\n",
    "k-fold는 sklearn의 model_selection 패키지에 있습니다.\n",
    "\n",
    "- KFold 대표 파라미터\n",
    "    - n_splits      (int)  : Fold의 개수 k 값\n",
    "    - shuffle       (bool) : 데이터를 쪼갤 때 섞을지 유무\n",
    "    - random_state  (int)  : 내부적으로 사용되는 난수값\n",
    "    \n",
    "#### ref\n",
    "- [Scikit-learn, KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)\n",
    "- [Scikit-learn, Stratified-KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold)\n",
    "- [Scikit-learn, Compare with KFold, StratifedKFold](https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html#sphx-glr-auto-examples-model-selection-plot-cv-indices-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iicqp2LODImk"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2cAG8VoMDIml"
   },
   "outputs": [],
   "source": [
    "for i, (trn_idx, val_idx) in enumerate(kf.split(data, label)):\n",
    "    x_train, y_train = data.iloc[trn_idx, :], label.iloc[trn_idx,]\n",
    "    x_valid, y_valid = data.iloc[val_idx, :], label.iloc[val_idx,]\n",
    "    \n",
    "    print('{} Fold, trn label\\n Class 0: {}, Class 1: {}, Class 2: {}'.format(i,   np.sum(y_train == 0), np.sum(y_train == 1), np.sum(y_train == 2)))\n",
    "    print('{} Fold, val label\\n Class 0: {}, Class 1: {}, Class 2: {}\\n'.format(i, np.sum(y_valid == 0), np.sum(y_valid == 1), np.sum(y_valid == 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppGlstcODIml"
   },
   "source": [
    "#### stratify k-Fold\n",
    "\n",
    "Stratified k-fold는 sklearn의 model_selection 패키지에 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "308yC6ArDIml"
   },
   "source": [
    "- StratifiedKFold 대표 파라미터\n",
    "    - n_splits      (int)  : Fold의 개수 k 값\n",
    "    - shuffle       (bool) : 데이터를 쪼갤 때 섞을지 유무\n",
    "    - random_state  (int)  : 내부적으로 사용되는 난수값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Am2VP7DBDIml"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L_S41RLiDIml"
   },
   "outputs": [],
   "source": [
    "for i, (trn_idx, val_idx) in enumerate(skf.split(data, label)):\n",
    "    x_train, y_train = data.iloc[trn_idx, :], label.iloc[trn_idx,]\n",
    "    x_valid, y_valid = data.iloc[val_idx, :], label.iloc[val_idx,]\n",
    "    \n",
    "    print('{} Fold, trn label\\n Class 0: {}, Class 1: {}, Class 2: {}'.format(i,   np.sum(y_train == 0), np.sum(y_train == 1), np.sum(y_train == 2)))\n",
    "    print('{} Fold, val label\\n Class 0: {}, Class 1: {}, Class 2: {}\\n'.format(i, np.sum(y_valid == 0), np.sum(y_valid == 1), np.sum(y_valid == 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6PNjv2kDImm"
   },
   "source": [
    "#### 전처리 프로세스 함수로 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W1siIkH9DImm"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "def preprocess(x_train, x_valid, x_test):\n",
    "    tmp_x_train = x_train.copy()\n",
    "    tmp_x_valid = x_valid.copy()\n",
    "    tmp_x_test  = x_test.copy()\n",
    "    \n",
    "    \n",
    "    # 결측치 처리\n",
    "    \n",
    "    \n",
    "    # 스케일링\n",
    "    \n",
    "\n",
    "    # 인코딩\n",
    "    \n",
    "    return tmp_x_train, tmp_x_valid, tmp_x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JDSt2BnMDImm"
   },
   "source": [
    "#### Cross Validation 해보기 (실습 15분)\n",
    "Stratified k-fold를 이용해 Cross Validation을 진행해 보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cKPBzzU-DImm"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics  import log_loss\n",
    "\n",
    "val_scores = list()\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for i, (trn_idx, val_idx) in enumerate(skf.split(data, label)):\n",
    "    x_train, y_train = data.iloc[trn_idx], label.iloc[trn_idx]\n",
    "    x_valid, y_valid = data.iloc[val_idx], label.iloc[val_idx]\n",
    "    \n",
    "    # 전처리\n",
    "    \n",
    "    \n",
    "    # 모델 정의\n",
    "    \n",
    "    \n",
    "    # 모델 학습\n",
    "    \n",
    "    \n",
    "    # 훈련, 검증 데이터 log_loss 확인\n",
    "    trn_logloss = \n",
    "    val_logloss = \n",
    "    print('{} Fold, train logloss : {:.4f}4, validation logloss : {:.4f}'.format(i, trn_logloss, val_logloss))\n",
    "    \n",
    "    val_scores.append(val_logloss)\n",
    "\n",
    "# 교차 검증 logloss 평균 계산하기\n",
    "print('Cross Validation Score : {:.4f}'.format(np.mean(val_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_H-4q_KDImm"
   },
   "source": [
    "## Ensemble\n",
    "개인적으로 앙상블은 머신러닝의 꽃이라고 생각합니다. 단일 모델로 좋은 성능을 이끄는 것도 중요하지만, 서로 다른 모델의 다양성을 고려하여 결과를 이끌어내는 앙상블은 응용할 수 있는 방법이 매우 많습니다. <br>\n",
    "그 중 대표적인 2가지 앙상블에 대해 실습하고 배워보도록 하겠습니다. \n",
    "\n",
    "### 1. Voting Ensemble\n",
    "이름에서 알 수 있듯이 각자의 모델이 투표를 하여 클래스를 선택하는 방식의 앙상블 입니다. <br>\n",
    "Voting 앙상블은 Sklearn 자체적으로 모델로써 지원을 하며, 사용하기도 매우 쉽습니다. <br>\n",
    "그리고 Hard, Soft로 Voting 방식이 나뉘는데, Hard는 라벨 값으로 투표를 하는 방식이고, Soft는 확률 값을 모두 더해 가장 높은 클래스를 선택합니다.\n",
    "\n",
    "Voting Classifier는 Sklearn의 ensemble 패키지에 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ezoP8SlKDImm"
   },
   "source": [
    "#### 1) 모델 불러오기 및 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DvoLbWnVDImm"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clfs = [['Logistic', LogisticRegression()],\n",
    "        ['RandomForest', RandomForestClassifier()],\n",
    "        ['MLP', MLPClassifier()]]\n",
    "\n",
    "vote_clf = VotingClassifier(clfs, voting='soft', n_jobs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8n5ykxNDImm"
   },
   "source": [
    "#### 2) 모델 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LTPbsOVDDImm",
    "outputId": "3b8de17e-4186-4ca8-9cf1-e621d827b18c"
   },
   "outputs": [],
   "source": [
    "# 여기서 x_train, y_train은 마지막 Fold\n",
    "vote_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7QOdhhcDImn"
   },
   "source": [
    "#### 3) 결과 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KeGIs4kLDImn",
    "outputId": "5e5a848a-85cc-4039-e1e6-77b618bae967"
   },
   "outputs": [],
   "source": [
    "print('Validation logloss : {:.4f}'.format(log_loss(y_valid, vote_clf.predict_proba(x_valid))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sePjVHYlDImo"
   },
   "source": [
    "### 2. Out-of-fold(OOF) Ensemble (같이 푸는 실습)\n",
    "OOF 앙상블은 KFold 교차 검증에서 생성되는 각 Fold에 대한 예측 값을 앙상블하는 기법으로 모델 검증과 함께 앙상블을 진행할 수 있다는 장점이 있습니다. <br>\n",
    "\n",
    "Cross Validation 파트에서 배웠던 KFold 코드를 재사용해 OOF 앙상블을 진행해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BNZQYcSLDImo"
   },
   "outputs": [],
   "source": [
    "val_scores = list()\n",
    "oof_pred = np.zeros((#맞는 차원 집어넣기))\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for i, (trn_idx, val_idx) in enumerate(skf.split(data, label)):\n",
    "    x_train, y_train = data.iloc[trn_idx, :], label.iloc[trn_idx,]\n",
    "    x_valid, y_valid = data.iloc[val_idx, :], label.iloc[val_idx,]\n",
    "    \n",
    "    # 전처리\n",
    "    \n",
    "    \n",
    "    # 모델 정의\n",
    "    \n",
    "    \n",
    "    # 모델 학습\n",
    "\n",
    "    \n",
    "    # 훈련, 검증 데이터 log_loss 확인\n",
    "    trn_logloss = \n",
    "    val_logloss = \n",
    "    print('{} Fold, train logloss : {:.4f}4, validation logloss : {:.4f}'.format(i, trn_logloss, val_logloss))\n",
    "    \n",
    "    val_scores.append(val_logloss)\n",
    "    \n",
    "    oof_pred += clf.predict_proba(x_test) / skf.n_splits \n",
    "\n",
    "# 교차 검증 정확도 평균 계산하기\n",
    "print('Cross Validation Score : {:.4f}'.format(np.mean(val_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KIuk-V6rDImo"
   },
   "outputs": [],
   "source": [
    "submit_path = join(BASE_DIR, 'data', 'MDC14', 'sample_submission.csv')\n",
    "\n",
    "submit = pd.read_csv(submit_path)\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hTTOpLmnDImo"
   },
   "outputs": [],
   "source": [
    "submit.iloc[:, 1:] = oof_pred\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A9ewVC8fDImo"
   },
   "outputs": [],
   "source": [
    "# submit.to_csv('oof_first_submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJCNyrtPDImo"
   },
   "source": [
    "## 실습 솔루션"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CAhA3qNjDImo"
   },
   "source": [
    "### 1) 전처리 함수 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hMV9fXRTDImo"
   },
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "def preprocess(x_train, x_valid, x_test):\n",
    "    tmp_x_train = x_train.copy()\n",
    "    tmp_x_valid = x_valid.copy()\n",
    "    tmp_x_test  = x_test.copy()\n",
    "    \n",
    "    tmp_x_train.reset_index(drop=True, inplace=True)\n",
    "    tmp_x_valid.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # 결측치 처리\n",
    "    imputer = SimpleImputer(strategy='most_frequent')\n",
    "    tmp_x_train[cat_columns] = imputer.fit_transform(tmp_x_train[cat_columns])\n",
    "    tmp_x_valid[cat_columns] = imputer.transform(tmp_x_valid[cat_columns])\n",
    "    tmp_x_test[cat_columns]  = imputer.transform(tmp_x_test[cat_columns])\n",
    "    \n",
    "    # 스케일링\n",
    "    scaler = StandardScaler()\n",
    "    tmp_x_train[num_columns] = scaler.fit_transform(tmp_x_train[num_columns])\n",
    "    tmp_x_valid[num_columns] = scaler.transform(tmp_x_valid[num_columns])\n",
    "    tmp_x_test[num_columns]  = scaler.transform(tmp_x_test[num_columns])\n",
    "\n",
    "    # 인코딩\n",
    "    ohe = OneHotEncoder(sparse=False)\n",
    "    ohe.fit(tmp_x_train[cat_columns])\n",
    "    \n",
    "    tmp_x_train_cat = pd.DataFrame(ohe.transform(tmp_x_train[cat_columns]))\n",
    "    tmp_x_valid_cat = pd.DataFrame(ohe.transform(tmp_x_valid[cat_columns]))\n",
    "    tmp_x_test_cat  = pd.DataFrame(ohe.transform(tmp_x_test[cat_columns]))\n",
    "    \n",
    "    tmp_x_train.drop(columns=cat_columns, inplace=True)\n",
    "    tmp_x_valid.drop(columns=cat_columns, inplace=True)\n",
    "    tmp_x_test.drop(columns=cat_columns, inplace=True)\n",
    "    \n",
    "    tmp_x_train = pd.concat([tmp_x_train, tmp_x_train_cat], axis=1)\n",
    "    tmp_x_valid = pd.concat([tmp_x_valid, tmp_x_valid_cat], axis=1)\n",
    "    tmp_x_test  = pd.concat([tmp_x_test, tmp_x_test_cat], axis=1)\n",
    "    \n",
    "    return tmp_x_train, tmp_x_valid, tmp_x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOXQeGXMDImp"
   },
   "source": [
    "### 2) Cross Validation  실습 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dn-jM-OIDImp"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics  import log_loss\n",
    "\n",
    "val_scores = list()\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for i, (trn_idx, val_idx) in enumerate(skf.split(data, label)):\n",
    "    x_train, y_train = data.iloc[trn_idx], label.iloc[trn_idx]\n",
    "    x_valid, y_valid = data.iloc[val_idx], label.iloc[val_idx]\n",
    "    \n",
    "    # 전처리\n",
    "    x_train, x_valid, x_test = preprocess(x_train, x_valid, test)\n",
    "    \n",
    "    # 모델 정의\n",
    "    model = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "    \n",
    "    # 모델 학습\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    # 훈련, 검증 데이터 log_loss 확인\n",
    "    trn_logloss = log_loss(y_train, model.predict_proba(x_train))\n",
    "    val_logloss = log_loss(y_valid, model.predict_proba(x_valid))\n",
    "    print('{} Fold, train logloss : {:.4f}4, validation logloss : {:.4f}'.format(i, trn_logloss, val_logloss))\n",
    "    \n",
    "    val_scores.append(val_logloss)\n",
    "\n",
    "# 교차 검증 logloss 평균 계산하기\n",
    "print('Cross Validation Score : {:.4f}'.format(np.mean(val_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f-ERn8KjDImp"
   },
   "outputs": [],
   "source": [
    "val_scores = list()\n",
    "oof_pred = np.zeros((test.shape[0], 3))\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for i, (trn_idx, val_idx) in enumerate(skf.split(data, label)):\n",
    "    x_train, y_train = data.iloc[trn_idx, :], label.iloc[trn_idx,]\n",
    "    x_valid, y_valid = data.iloc[val_idx, :], label.iloc[val_idx,]\n",
    "    \n",
    "    # 전처리\n",
    "    x_train, x_valid, x_test = preprocess(x_train, x_valid, test)\n",
    "    \n",
    "    # 모델 정의\n",
    "    clf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "    \n",
    "    # 모델 학습\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "    # 훈련, 검증 데이터 log_loss 확인\n",
    "    trn_logloss = log_loss(y_train, model.predict_proba(x_train))\n",
    "    val_logloss = log_loss(y_valid, model.predict_proba(x_valid))\n",
    "    print('{} Fold, train logloss : {:.4f}4, validation logloss : {:.4f}'.format(i, trn_logloss, val_logloss))\n",
    "    \n",
    "    val_scores.append(val_logloss)\n",
    "    \n",
    "    oof_pred += clf.predict_proba(x_test) / skf.n_splits \n",
    "\n",
    "# 교차 검증 정확도 평균 계산하기\n",
    "print('Cross Validation Score : {:.4f}'.format(np.mean(val_scores)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab_03) Model Validation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Kyle",
   "language": "python",
   "name": "kyle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
